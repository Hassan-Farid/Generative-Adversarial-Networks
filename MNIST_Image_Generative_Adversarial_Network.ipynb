{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST Image Generative Adversarial Network.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpRCHpFIvSR6",
        "outputId": "36bc7b28-d347-492f-8fea-4095764c892b"
      },
      "source": [
        "#Importing save state folder from drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1VE93WRrsqd"
      },
      "source": [
        "## Creating a Binary Classifier Discriminator:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5Iq3OA3rrGy"
      },
      "source": [
        "#Importing necessary modules\n",
        "import sys\n",
        "import numpy as np\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "#Filling in the Discriminator Class Structure for given scenario\n",
        "class Discriminator(object):\n",
        "    \n",
        "    def __init__(self, width=28, height=28, channels=1, latent_size=100):\n",
        "        \n",
        "        #Creating internal variables\n",
        "        self.CAPACITY = width * height * channels #Computing the total capacity of the model\n",
        "        self.SHAPE = (width, height, channels) #Computing the shape of data for the model\n",
        "        self.OPTIMIZER = Adam(lr=0.0002, decay=8e-9) #Creating ADAM optimizer for the model\n",
        "        \n",
        "        #Initializing the Discriminator model\n",
        "        self.Discriminator = self.model()\n",
        "        \n",
        "        #Compiling the model for binary crossentropy loss as it is a binary classifier\n",
        "        self.Discriminator.compile(loss='binary_crossentropy', optimizer=self.OPTIMIZER, metrics=['accuracy'])\n",
        "        \n",
        "        #Displaying summary of the Discriminator model\n",
        "        self.Discriminator.summary()\n",
        "        \n",
        "    def model(self):\n",
        "        \n",
        "        #Instantiating a Sequential Model for binary classification task\n",
        "        model = Sequential()\n",
        "        \n",
        "        #Adding the first layer to the network \n",
        "        model.add(Flatten(input_shape = self.SHAPE)) #The layer flattens the data into a single data stream\n",
        "        \n",
        "        #Adding the next set of layers to the network\n",
        "        model.add(Dense(self.CAPACITY, input_shape=self.SHAPE)) #The dense layer is fully connected with next layer\n",
        "        model.add(LeakyReLU(alpha=0.2)) #Leaky ReLU layer ensures use of small gradients\n",
        "        \n",
        "        #Adding the next set of layers to the network\n",
        "        model.add(Dense(int(self.CAPACITY/2)))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        \n",
        "        #Adding the output layer to the network\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        return model\n",
        "    \n",
        "    def summary(self):\n",
        "        \n",
        "        #Returning summary of the Discriminator model\n",
        "        return self.Discriminator.summary()\n",
        "    \n",
        "    def save_model(self):\n",
        "        \n",
        "        #Plotting photographic version of model structure\n",
        "        plot_model(self.Discriminator.model, to_file=\"/content/drive/Data/Discriminator_Model.png\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "978Je7gTsLvU"
      },
      "source": [
        "## Creating Simple Generator Model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iob6CYRsQFY"
      },
      "source": [
        "#Importing necessary modules\n",
        "import sys\n",
        "import numpy as np\n",
        "from keras.layers import Dense, Reshape\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "#Filling in the Generator Base Class for given scenario\n",
        "class Generator(object):\n",
        "    \n",
        "    #Initialization Method\n",
        "    def __init__(self, width=28, height=28, channels=1, latent_size=100):\n",
        "        \n",
        "        #Creating internal variables\n",
        "        self.W = width #Storing the width of image\n",
        "        self.H = height #Storing the height of image\n",
        "        self.C = channels #Storing the channels for the image\n",
        "        self.OPTIMIZER = Adam(lr=0.002, decay=8e-9) #Creating Adam optimizer for model development\n",
        "        \n",
        "        #Storing the latent space size for the generator\n",
        "        self.LATENT_SPACE_SIZE = latent_size\n",
        "        \n",
        "        #Creating a latent space for the generator model via a Gaussian distribution\n",
        "        self.latent_space = np.random.normal(0, 1, (self.LATENT_SPACE_SIZE,))\n",
        "        \n",
        "        #Instantiating the generator model object\n",
        "        self.Generator = self.model()\n",
        "        \n",
        "        #Compiling the generator model with binary crossentropy loss and Adam optimizer\n",
        "        self.Generator.compile(loss=\"binary_crossentropy\", optimizer=self.OPTIMIZER)\n",
        "        \n",
        "        #Displaying the summary of the generator model\n",
        "        self.Generator.summary()\n",
        "    \n",
        "    #Model Instantiation Method\n",
        "    def model(self, block_starting_size=128, num_blocks=4):\n",
        "        \n",
        "        #Instantiating a Sequential Model for Generator model\n",
        "        model = Sequential()\n",
        "        \n",
        "        #Storing the initialized block size for number of nodes \n",
        "        block_size = block_starting_size\n",
        "        \n",
        "        #Generate the first block of layers for the network\n",
        "        model.add(Dense(block_size, input_shape=(self.LATENT_SPACE_SIZE,))) #Creates a basic input Dense interconnected layer\n",
        "        model.add(LeakyReLU(alpha=0.2)) #Creates a LeakyReLU layer to prevent vanishing gradients and non-activated neurons\n",
        "        model.add(BatchNormalization(momentum=0.8)) #Performs BatchNormalization to clean layer by normalizing activations\n",
        "    \n",
        "        #Adding the remaining blocks of layers with double the block size with each block\n",
        "        for i in range(num_blocks - 1):\n",
        "            block_size = block_size * 2\n",
        "            model.add(Dense(block_size))\n",
        "            model.add(LeakyReLU(alpha=0.2))\n",
        "            model.add(BatchNormalization(momentum=0.8))\n",
        "            \n",
        "        #Reconstructing output to the input image shape\n",
        "        model.add(Dense(self.W * self.H * self.C, activation='tanh'))\n",
        "        model.add(Reshape((self.W, self.H, self.C)))\n",
        "        \n",
        "        #Returning the model\n",
        "        return model\n",
        "        \n",
        "    #Summarization Method\n",
        "    def summary(self):\n",
        "        #Produces summary of the model on the screen\n",
        "        return self.Generator.summary()\n",
        "    \n",
        "    #Saving Method\n",
        "    def save_model(self):\n",
        "        #Saves the model structure to a file in particular folder\n",
        "        plot_model(self.Generator.model, to_file='/content/drive/Data/Generator_Model.png')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPEfGxd7sdeW"
      },
      "source": [
        "## Creating the Adversarial Network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hnq3qOJ7sg2J"
      },
      "source": [
        "#Creating GAN Base Class Structure\n",
        "class GAN(object):\n",
        "    \n",
        "    #Initialization Method\n",
        "    def __init__(self, discriminator, generator):\n",
        "        self.OPTIMIZER = Adam(lr=0.002, decay=8e-9) #Creating an Adam optimizer\n",
        "        self.Generator = generator #Storing the provided generator model\n",
        "        self.Discriminator = discriminator #Storing the provided discriminator model\n",
        "        \n",
        "        self.Discriminator.trainable = False #Trainability for discriminator turned off for adversarial training\n",
        "        self.gan_model = self.model() #Creating the adversarial model\n",
        "        self.gan_model.compile(loss='binary_crossentropy', optimizer=self.OPTIMIZER) #Compiling adversarial model\n",
        "        self.gan_model.summary() #Displaying summary of the adversarial model\n",
        "    \n",
        "    #Model Instantiation Method\n",
        "    def model(self):\n",
        "        model = Sequential() #Creating a Sequential model\n",
        "        model.add(self.Generator) #Adding the generator model to the network\n",
        "        model.add(self.Discriminator) #Adding the discriminator model to the network\n",
        "        return model\n",
        "    \n",
        "    #Summarization Method\n",
        "    def summary(self):\n",
        "        #Produces summary of the model on the screen\n",
        "        self.gan_model.summary()\n",
        "    \n",
        "    #Saving Method\n",
        "    def save_model(self):\n",
        "        #Saves the model structure to file in a particular folder\n",
        "        plot_model(self.gan_model.model, to_file='/content/drive/Data/GAN_Model.png')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1mfVl6ZsliJ"
      },
      "source": [
        "## Training GAN Model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXdHu_iNso-G"
      },
      "source": [
        "#Importing the necessary modules\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from random import randint\n",
        "\n",
        "#Creating the Trainer class to train the adversarial network\n",
        "class Trainer:\n",
        "    \n",
        "    def __init__(self, width=28, height=28, channels=1, latent_size=100, epochs=50000, batch=32, checkpoint=50, model_type=-1):\n",
        "        #Creating internal variables\n",
        "        self.W = width #Storing the width of the data\n",
        "        self.H = height #Storing the height of the data\n",
        "        self.C = channels #Storing the channels of the data\n",
        "        self.EPOCHS = epochs #Storing the number of epochs for the data\n",
        "        self.BATCH = batch #Storing the number of batches for the data\n",
        "        self.CHECKPOINT = checkpoint #Storing the checkpoint for the data\n",
        "        self.model_type = model_type #Storing the model type for the model\n",
        "        self.LATENT_SPACE_SIZE = latent_size #Storing the latent size for the image\n",
        "        \n",
        "        #Creating Generator model for training\n",
        "        self.generator = Generator(height=self.H, width=self.W, channels=self.C, latent_size=self.LATENT_SPACE_SIZE)\n",
        "        \n",
        "        #Creating Discriminator model for training\n",
        "        self.discriminator = Discriminator(height=self.H, width=self.W, channels=self.C)\n",
        "        \n",
        "        #Creating Adversarial model for training\n",
        "        self.gan = GAN(generator=self.generator.Generator, discriminator=self.discriminator.Discriminator)\n",
        "        \n",
        "        #Loading the mnist data for each Trainer instance\n",
        "        self.load_MNIST()\n",
        "        \n",
        "    #Creating the dataset loading method\n",
        "    def load_MNIST(self, model_type=3):\n",
        "        allowed_types = list(range(-1,10)) #Creating list of allowed model types\n",
        "        if self.model_type not in allowed_types:\n",
        "            print(\"ERROR! Only integer values ranging within the interval [-1, 9] are allowed!\")\n",
        "            \n",
        "        #Loading the training and testing data\n",
        "        (self.X_train, self.Y_train), (_, _) = mnist.load_data()\n",
        "        \n",
        "        #Checking model type (if it is for a specific output or all outputs) \n",
        "        if self.model_type != -1:\n",
        "            self.X_train = self.X_train[np.where(self.Y_train == int(self.model_type))[0]]\n",
        "            \n",
        "        #If model type is -1 (for all outputs)\n",
        "        self.X_train = (np.float32(self.X_train) - 127.5) / 127.5\n",
        "        self.X_train = np.expand_dims(self.X_train, axis=3)\n",
        "        \n",
        "        return\n",
        "    \n",
        "    #Creating the model training method\n",
        "    def train(self):\n",
        "        #Iterating for each epoch of training set\n",
        "        for e in range(self.EPOCHS):\n",
        "            #Grabbing a batch of images (half of the images)\n",
        "            count_real_images = int(self.BATCH / 2)\n",
        "            \n",
        "            #Create a random index for the batch\n",
        "            starting_index = randint(0, len(self.X_train) - count_real_images)\n",
        "            \n",
        "            #Extracting the half the number of images based on the starting index\n",
        "            real_images_raw = self.X_train[starting_index : (starting_index + count_real_images)]\n",
        "            \n",
        "            #Creating real images and labels for training the batch data\n",
        "            x_real_images = real_images_raw.reshape(count_real_images, self.W, self.H, self.C)\n",
        "            y_real_labels = np.ones([count_real_images, 1])\n",
        "            \n",
        "            #Creating latent space for the images to be generated\n",
        "            latent_space_samples = self.sample_latent_space(count_real_images)\n",
        "            \n",
        "            #Generating images for the batch of images via the Generator model\n",
        "            x_generated_images = self.generator.Generator.predict(latent_space_samples)\n",
        "            \n",
        "            #Generating labels for the generated images\n",
        "            y_generated_labels = np.zeros([self.BATCH - count_real_images, 1])\n",
        "            \n",
        "            #Concatenating both the batches (real images and generated ones) for training on discriminator\n",
        "            x_batch = np.concatenate([x_real_images, x_generated_images])\n",
        "            y_batch = np.concatenate([y_real_labels, y_generated_labels])\n",
        "            \n",
        "            #Training the Discriminator on the batch\n",
        "            discriminator_loss = self.discriminator.Discriminator.train_on_batch(x_batch, y_batch)[0]\n",
        "            \n",
        "            #Generating noise to train Generator model\n",
        "            x_latent_space_samples = self.sample_latent_space(self.BATCH)\n",
        "            y_generated_labels = np.ones([self.BATCH, 1])\n",
        "            \n",
        "            #Training the Generator on the batch\n",
        "            generator_loss = self.gan.gan_model.train_on_batch(x_latent_space_samples, y_generated_labels)\n",
        "            \n",
        "            #Viewing the loss metrics for the batch\n",
        "            print(\"Epoch: {} , [Discriminator :: Loss : {}] , [Generator :: Loss : {}]\".format(e, discriminator_loss, generator_loss))\n",
        "            \n",
        "            #Saving checkpoint \n",
        "            if e % self.CHECKPOINT == 0:\n",
        "                self.plot_checkpoint(e)\n",
        "            \n",
        "        return\n",
        "    \n",
        "    #Helper method : A wrapper method to produce latent space easily\n",
        "    def sample_latent_space(self, instances):\n",
        "        return np.random.normal(0, 1, (instances, self.LATENT_SPACE_SIZE))\n",
        "    \n",
        "    #Helper method: Plotting checkpoint on reaching checkpoint epoch\n",
        "    def plot_checkpoint(self, e):\n",
        "        #Generating filename to save to\n",
        "        filename = \"/content/drive/Data/samples/\" + str(e) + \".png\"\n",
        "        \n",
        "        #Creating noise from latent space and generating an image via Generator\n",
        "        noise = self.sample_latent_space(16)\n",
        "        images = self.generator.Generator.predict(noise)\n",
        "        \n",
        "        #Plotting the newly generated images at each epoch checkpoint\n",
        "        plt.figure(figsize=(10,10))\n",
        "        for i in range(images.shape[0]):\n",
        "            plt.subplot(4, 4, i+1) #Creating 4x4 grid for 16 generated images\n",
        "            image = images[i, :, :, :]\n",
        "            image = np.reshape(image, (self.H, self.W))\n",
        "            plt.imshow(image, cmap='gray')\n",
        "            plt.axis('off')\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            #plt.savefig(filename)\n",
        "            plt.close('all')\n",
        "            \n",
        "        return"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qpTDg_wstlY",
        "outputId": "2bc0a012-27d1-49d0-d9a2-a7ea99048b98"
      },
      "source": [
        "#Running the Trainer class to Train the adversarial network\n",
        "#Defining internal variable values\n",
        "HEIGHT = 28\n",
        "WIDTH = 28\n",
        "CHANNEL = 1\n",
        "LATENT_SPACE_SIZE = 100\n",
        "EPOCHS = 500\n",
        "BATCH = 4\n",
        "CHECKPOINT = 50\n",
        "MODEL_TYPE = -1\n",
        "\n",
        "#Creating the trainer object\n",
        "trainer = Trainer(height=HEIGHT, width=WIDTH, channels=CHANNEL, latent_size=LATENT_SPACE_SIZE, epochs=EPOCHS, batch=BATCH ,checkpoint=CHECKPOINT, model_type=MODEL_TYPE)\n",
        "\n",
        "#Training the trainer object to get results\n",
        "trainer.train()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_48 (Dense)             (None, 128)               12928     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_36 (LeakyReLU)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_37 (LeakyReLU)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_38 (LeakyReLU)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_39 (LeakyReLU)   (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 784)               803600    \n",
            "_________________________________________________________________\n",
            "reshape_6 (Reshape)          (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 1,514,128\n",
            "Trainable params: 1,510,288\n",
            "Non-trainable params: 3,840\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_6 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 784)               615440    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_40 (LeakyReLU)   (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 392)               307720    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_41 (LeakyReLU)   (None, 392)               0         \n",
            "_________________________________________________________________\n",
            "dense_55 (Dense)             (None, 1)                 393       \n",
            "=================================================================\n",
            "Total params: 923,553\n",
            "Trainable params: 923,553\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_18 (Sequential)   (None, 28, 28, 1)         1514128   \n",
            "_________________________________________________________________\n",
            "sequential_19 (Sequential)   (None, 1)                 923553    \n",
            "=================================================================\n",
            "Total params: 2,437,681\n",
            "Trainable params: 1,510,288\n",
            "Non-trainable params: 927,393\n",
            "_________________________________________________________________\n",
            "Epoch: 0 , [Discriminator :: Loss : 0.7276641130447388] , [Generator :: Loss : 0.754278838634491]\n",
            "Epoch: 1 , [Discriminator :: Loss : 0.4011194109916687] , [Generator :: Loss : 0.6167484521865845]\n",
            "Epoch: 2 , [Discriminator :: Loss : 0.39974403381347656] , [Generator :: Loss : 0.5798271894454956]\n",
            "Epoch: 3 , [Discriminator :: Loss : 0.41850852966308594] , [Generator :: Loss : 0.6167799234390259]\n",
            "Epoch: 4 , [Discriminator :: Loss : 0.5447639226913452] , [Generator :: Loss : 0.7211614847183228]\n",
            "Epoch: 5 , [Discriminator :: Loss : 0.4283958077430725] , [Generator :: Loss : 0.6548447608947754]\n",
            "Epoch: 6 , [Discriminator :: Loss : 0.5442222952842712] , [Generator :: Loss : 0.36591634154319763]\n",
            "Epoch: 7 , [Discriminator :: Loss : 0.7319610714912415] , [Generator :: Loss : 0.5049747228622437]\n",
            "Epoch: 8 , [Discriminator :: Loss : 0.7992703318595886] , [Generator :: Loss : 0.7855981588363647]\n",
            "Epoch: 9 , [Discriminator :: Loss : 0.4713272452354431] , [Generator :: Loss : 0.6676079630851746]\n",
            "Epoch: 10 , [Discriminator :: Loss : 0.34605348110198975] , [Generator :: Loss : 1.1995186805725098]\n",
            "Epoch: 11 , [Discriminator :: Loss : 0.5737229585647583] , [Generator :: Loss : 0.719590425491333]\n",
            "Epoch: 12 , [Discriminator :: Loss : 0.6726857423782349] , [Generator :: Loss : 1.059462547302246]\n",
            "Epoch: 13 , [Discriminator :: Loss : 0.678787112236023] , [Generator :: Loss : 1.3342490196228027]\n",
            "Epoch: 14 , [Discriminator :: Loss : 0.44341841340065] , [Generator :: Loss : 1.0576895475387573]\n",
            "Epoch: 15 , [Discriminator :: Loss : 0.09343671798706055] , [Generator :: Loss : 0.6936607360839844]\n",
            "Epoch: 16 , [Discriminator :: Loss : 0.3056483268737793] , [Generator :: Loss : 1.376676082611084]\n",
            "Epoch: 17 , [Discriminator :: Loss : 0.17878633737564087] , [Generator :: Loss : 0.8346809148788452]\n",
            "Epoch: 18 , [Discriminator :: Loss : 0.1654394567012787] , [Generator :: Loss : 2.2924113273620605]\n",
            "Epoch: 19 , [Discriminator :: Loss : 0.017917906865477562] , [Generator :: Loss : 1.9577276706695557]\n",
            "Epoch: 20 , [Discriminator :: Loss : 0.17461037635803223] , [Generator :: Loss : 1.6013902425765991]\n",
            "Epoch: 21 , [Discriminator :: Loss : 0.19581322371959686] , [Generator :: Loss : 3.1617982387542725]\n",
            "Epoch: 22 , [Discriminator :: Loss : 0.13310503959655762] , [Generator :: Loss : 2.1893527507781982]\n",
            "Epoch: 23 , [Discriminator :: Loss : 0.0553598552942276] , [Generator :: Loss : 2.0081210136413574]\n",
            "Epoch: 24 , [Discriminator :: Loss : 0.012377237901091576] , [Generator :: Loss : 3.2357640266418457]\n",
            "Epoch: 25 , [Discriminator :: Loss : 0.034942809492349625] , [Generator :: Loss : 2.48773455619812]\n",
            "Epoch: 26 , [Discriminator :: Loss : 0.019245902076363564] , [Generator :: Loss : 2.3836209774017334]\n",
            "Epoch: 27 , [Discriminator :: Loss : 0.06019485741853714] , [Generator :: Loss : 2.8169493675231934]\n",
            "Epoch: 28 , [Discriminator :: Loss : 0.051288336515426636] , [Generator :: Loss : 2.7056493759155273]\n",
            "Epoch: 29 , [Discriminator :: Loss : 0.022478055208921432] , [Generator :: Loss : 2.636064052581787]\n",
            "Epoch: 30 , [Discriminator :: Loss : 0.05034002661705017] , [Generator :: Loss : 3.4207863807678223]\n",
            "Epoch: 31 , [Discriminator :: Loss : 0.09024389833211899] , [Generator :: Loss : 2.980483055114746]\n",
            "Epoch: 32 , [Discriminator :: Loss : 0.12219391018152237] , [Generator :: Loss : 1.9914135932922363]\n",
            "Epoch: 33 , [Discriminator :: Loss : 0.06352437287569046] , [Generator :: Loss : 3.4114344120025635]\n",
            "Epoch: 34 , [Discriminator :: Loss : 0.015045911073684692] , [Generator :: Loss : 3.5784835815429688]\n",
            "Epoch: 35 , [Discriminator :: Loss : 0.015386167913675308] , [Generator :: Loss : 3.1301639080047607]\n",
            "Epoch: 36 , [Discriminator :: Loss : 0.006713481619954109] , [Generator :: Loss : 2.6394569873809814]\n",
            "Epoch: 37 , [Discriminator :: Loss : 0.011142386123538017] , [Generator :: Loss : 2.9323675632476807]\n",
            "Epoch: 38 , [Discriminator :: Loss : 0.04658326879143715] , [Generator :: Loss : 2.8252639770507812]\n",
            "Epoch: 39 , [Discriminator :: Loss : 0.021098677068948746] , [Generator :: Loss : 2.560070037841797]\n",
            "Epoch: 40 , [Discriminator :: Loss : 0.008855888620018959] , [Generator :: Loss : 1.9652369022369385]\n",
            "Epoch: 41 , [Discriminator :: Loss : 0.03691308945417404] , [Generator :: Loss : 2.545158624649048]\n",
            "Epoch: 42 , [Discriminator :: Loss : 0.05999024584889412] , [Generator :: Loss : 2.5593631267547607]\n",
            "Epoch: 43 , [Discriminator :: Loss : 0.004536604043096304] , [Generator :: Loss : 3.2671613693237305]\n",
            "Epoch: 44 , [Discriminator :: Loss : 0.023904215544462204] , [Generator :: Loss : 2.386310338973999]\n",
            "Epoch: 45 , [Discriminator :: Loss : 0.09326313436031342] , [Generator :: Loss : 3.650294065475464]\n",
            "Epoch: 46 , [Discriminator :: Loss : 0.002879665233194828] , [Generator :: Loss : 2.989366054534912]\n",
            "Epoch: 47 , [Discriminator :: Loss : 0.010077739134430885] , [Generator :: Loss : 2.8544695377349854]\n",
            "Epoch: 48 , [Discriminator :: Loss : 0.21048419177532196] , [Generator :: Loss : 3.0844740867614746]\n",
            "Epoch: 49 , [Discriminator :: Loss : 0.00798096600919962] , [Generator :: Loss : 1.7860488891601562]\n",
            "Epoch: 50 , [Discriminator :: Loss : 0.02246680110692978] , [Generator :: Loss : 3.067140579223633]\n",
            "Epoch: 51 , [Discriminator :: Loss : 0.13569842278957367] , [Generator :: Loss : 2.8109211921691895]\n",
            "Epoch: 52 , [Discriminator :: Loss : 0.0028825143817812204] , [Generator :: Loss : 2.765408515930176]\n",
            "Epoch: 53 , [Discriminator :: Loss : 0.045508310198783875] , [Generator :: Loss : 2.929434061050415]\n",
            "Epoch: 54 , [Discriminator :: Loss : 0.030184201896190643] , [Generator :: Loss : 2.9721760749816895]\n",
            "Epoch: 55 , [Discriminator :: Loss : 0.0024398548994213343] , [Generator :: Loss : 3.352893590927124]\n",
            "Epoch: 56 , [Discriminator :: Loss : 0.002945023588836193] , [Generator :: Loss : 3.1350409984588623]\n",
            "Epoch: 57 , [Discriminator :: Loss : 0.00908169150352478] , [Generator :: Loss : 3.019001007080078]\n",
            "Epoch: 58 , [Discriminator :: Loss : 0.0032702696043998003] , [Generator :: Loss : 2.0897951126098633]\n",
            "Epoch: 59 , [Discriminator :: Loss : 0.004876230377703905] , [Generator :: Loss : 3.0134334564208984]\n",
            "Epoch: 60 , [Discriminator :: Loss : 0.16717985272407532] , [Generator :: Loss : 1.9347262382507324]\n",
            "Epoch: 61 , [Discriminator :: Loss : 0.0030624528881162405] , [Generator :: Loss : 3.881941795349121]\n",
            "Epoch: 62 , [Discriminator :: Loss : 0.11485826969146729] , [Generator :: Loss : 2.731574535369873]\n",
            "Epoch: 63 , [Discriminator :: Loss : 0.10538429766893387] , [Generator :: Loss : 3.3713390827178955]\n",
            "Epoch: 64 , [Discriminator :: Loss : 0.017544126138091087] , [Generator :: Loss : 2.7727890014648438]\n",
            "Epoch: 65 , [Discriminator :: Loss : 0.007629741914570332] , [Generator :: Loss : 2.2946815490722656]\n",
            "Epoch: 66 , [Discriminator :: Loss : 0.004913778975605965] , [Generator :: Loss : 3.5632071495056152]\n",
            "Epoch: 67 , [Discriminator :: Loss : 0.0037068775855004787] , [Generator :: Loss : 2.5063092708587646]\n",
            "Epoch: 68 , [Discriminator :: Loss : 0.012001439929008484] , [Generator :: Loss : 2.0284886360168457]\n",
            "Epoch: 69 , [Discriminator :: Loss : 0.01568521000444889] , [Generator :: Loss : 2.536142349243164]\n",
            "Epoch: 70 , [Discriminator :: Loss : 0.7781116962432861] , [Generator :: Loss : 3.307656764984131]\n",
            "Epoch: 71 , [Discriminator :: Loss : 0.009680614806711674] , [Generator :: Loss : 3.3050360679626465]\n",
            "Epoch: 72 , [Discriminator :: Loss : 0.11475405097007751] , [Generator :: Loss : 3.356027841567993]\n",
            "Epoch: 73 , [Discriminator :: Loss : 0.03088485449552536] , [Generator :: Loss : 3.7045865058898926]\n",
            "Epoch: 74 , [Discriminator :: Loss : 0.28361883759498596] , [Generator :: Loss : 3.2289021015167236]\n",
            "Epoch: 75 , [Discriminator :: Loss : 0.14540889859199524] , [Generator :: Loss : 4.364185333251953]\n",
            "Epoch: 76 , [Discriminator :: Loss : 0.037540268152952194] , [Generator :: Loss : 4.256631851196289]\n",
            "Epoch: 77 , [Discriminator :: Loss : 0.038662079721689224] , [Generator :: Loss : 4.348660945892334]\n",
            "Epoch: 78 , [Discriminator :: Loss : 0.052018340677022934] , [Generator :: Loss : 3.3254916667938232]\n",
            "Epoch: 79 , [Discriminator :: Loss : 0.04314054921269417] , [Generator :: Loss : 4.20731258392334]\n",
            "Epoch: 80 , [Discriminator :: Loss : 0.06659942865371704] , [Generator :: Loss : 4.039840221405029]\n",
            "Epoch: 81 , [Discriminator :: Loss : 0.031589575111866] , [Generator :: Loss : 3.6092376708984375]\n",
            "Epoch: 82 , [Discriminator :: Loss : 0.11656971275806427] , [Generator :: Loss : 3.6492016315460205]\n",
            "Epoch: 83 , [Discriminator :: Loss : 0.04884582385420799] , [Generator :: Loss : 3.2333712577819824]\n",
            "Epoch: 84 , [Discriminator :: Loss : 0.06683050841093063] , [Generator :: Loss : 3.884547233581543]\n",
            "Epoch: 85 , [Discriminator :: Loss : 0.010086786933243275] , [Generator :: Loss : 2.920433759689331]\n",
            "Epoch: 86 , [Discriminator :: Loss : 0.0019343569874763489] , [Generator :: Loss : 2.8513567447662354]\n",
            "Epoch: 87 , [Discriminator :: Loss : 0.001534859649837017] , [Generator :: Loss : 2.6314327716827393]\n",
            "Epoch: 88 , [Discriminator :: Loss : 0.011771025136113167] , [Generator :: Loss : 2.2645750045776367]\n",
            "Epoch: 89 , [Discriminator :: Loss : 0.03440198302268982] , [Generator :: Loss : 2.768221616744995]\n",
            "Epoch: 90 , [Discriminator :: Loss : 0.010978427715599537] , [Generator :: Loss : 2.723526954650879]\n",
            "Epoch: 91 , [Discriminator :: Loss : 0.006741313263773918] , [Generator :: Loss : 1.4293855428695679]\n",
            "Epoch: 92 , [Discriminator :: Loss : 0.125228613615036] , [Generator :: Loss : 2.5804123878479004]\n",
            "Epoch: 93 , [Discriminator :: Loss : 0.017606394365429878] , [Generator :: Loss : 1.6849894523620605]\n",
            "Epoch: 94 , [Discriminator :: Loss : 0.004314664751291275] , [Generator :: Loss : 2.108208179473877]\n",
            "Epoch: 95 , [Discriminator :: Loss : 0.00898266863077879] , [Generator :: Loss : 3.3114941120147705]\n",
            "Epoch: 96 , [Discriminator :: Loss : 0.24696533381938934] , [Generator :: Loss : 1.6637098789215088]\n",
            "Epoch: 97 , [Discriminator :: Loss : 0.018988877534866333] , [Generator :: Loss : 2.140185594558716]\n",
            "Epoch: 98 , [Discriminator :: Loss : 0.047204263508319855] , [Generator :: Loss : 2.7335193157196045]\n",
            "Epoch: 99 , [Discriminator :: Loss : 0.0883733257651329] , [Generator :: Loss : 1.9303768873214722]\n",
            "Epoch: 100 , [Discriminator :: Loss : 0.0012930654920637608] , [Generator :: Loss : 2.0083606243133545]\n",
            "Epoch: 101 , [Discriminator :: Loss : 0.005516528617590666] , [Generator :: Loss : 1.8244524002075195]\n",
            "Epoch: 102 , [Discriminator :: Loss : 0.016832537949085236] , [Generator :: Loss : 2.343693256378174]\n",
            "Epoch: 103 , [Discriminator :: Loss : 0.9962583780288696] , [Generator :: Loss : 3.2170372009277344]\n",
            "Epoch: 104 , [Discriminator :: Loss : 0.01959238573908806] , [Generator :: Loss : 3.034797430038452]\n",
            "Epoch: 105 , [Discriminator :: Loss : 0.006192972883582115] , [Generator :: Loss : 2.2276804447174072]\n",
            "Epoch: 106 , [Discriminator :: Loss : 0.0032224771566689014] , [Generator :: Loss : 3.238809585571289]\n",
            "Epoch: 107 , [Discriminator :: Loss : 0.09428314864635468] , [Generator :: Loss : 2.9536561965942383]\n",
            "Epoch: 108 , [Discriminator :: Loss : 0.14535631239414215] , [Generator :: Loss : 3.674290657043457]\n",
            "Epoch: 109 , [Discriminator :: Loss : 0.04635271057486534] , [Generator :: Loss : 3.2395949363708496]\n",
            "Epoch: 110 , [Discriminator :: Loss : 0.017647597938776016] , [Generator :: Loss : 4.790073394775391]\n",
            "Epoch: 111 , [Discriminator :: Loss : 0.0409027561545372] , [Generator :: Loss : 3.955462694168091]\n",
            "Epoch: 112 , [Discriminator :: Loss : 0.0810241848230362] , [Generator :: Loss : 3.664940595626831]\n",
            "Epoch: 113 , [Discriminator :: Loss : 0.04245997965335846] , [Generator :: Loss : 3.5360143184661865]\n",
            "Epoch: 114 , [Discriminator :: Loss : 0.03006412647664547] , [Generator :: Loss : 3.0873119831085205]\n",
            "Epoch: 115 , [Discriminator :: Loss : 0.03515554592013359] , [Generator :: Loss : 3.0676074028015137]\n",
            "Epoch: 116 , [Discriminator :: Loss : 0.18604278564453125] , [Generator :: Loss : 2.6448891162872314]\n",
            "Epoch: 117 , [Discriminator :: Loss : 0.02539213001728058] , [Generator :: Loss : 3.232470750808716]\n",
            "Epoch: 118 , [Discriminator :: Loss : 0.039165254682302475] , [Generator :: Loss : 2.187096118927002]\n",
            "Epoch: 119 , [Discriminator :: Loss : 0.20980525016784668] , [Generator :: Loss : 2.0396571159362793]\n",
            "Epoch: 120 , [Discriminator :: Loss : 0.38595545291900635] , [Generator :: Loss : 3.190178871154785]\n",
            "Epoch: 121 , [Discriminator :: Loss : 0.16463245451450348] , [Generator :: Loss : 3.6580755710601807]\n",
            "Epoch: 122 , [Discriminator :: Loss : 0.06972664594650269] , [Generator :: Loss : 4.362278938293457]\n",
            "Epoch: 123 , [Discriminator :: Loss : 0.03280698508024216] , [Generator :: Loss : 4.079659461975098]\n",
            "Epoch: 124 , [Discriminator :: Loss : 0.043070778250694275] , [Generator :: Loss : 5.269428253173828]\n",
            "Epoch: 125 , [Discriminator :: Loss : 0.082857646048069] , [Generator :: Loss : 5.729300498962402]\n",
            "Epoch: 126 , [Discriminator :: Loss : 0.03457781672477722] , [Generator :: Loss : 4.607264995574951]\n",
            "Epoch: 127 , [Discriminator :: Loss : 0.1591229885816574] , [Generator :: Loss : 4.184770584106445]\n",
            "Epoch: 128 , [Discriminator :: Loss : 0.12482942640781403] , [Generator :: Loss : 4.224135398864746]\n",
            "Epoch: 129 , [Discriminator :: Loss : 0.2406918853521347] , [Generator :: Loss : 3.597612142562866]\n",
            "Epoch: 130 , [Discriminator :: Loss : 0.0026997176464647055] , [Generator :: Loss : 3.5358099937438965]\n",
            "Epoch: 131 , [Discriminator :: Loss : 0.0053629325702786446] , [Generator :: Loss : 3.6982555389404297]\n",
            "Epoch: 132 , [Discriminator :: Loss : 0.0016478695906698704] , [Generator :: Loss : 3.216984272003174]\n",
            "Epoch: 133 , [Discriminator :: Loss : 0.01228612381964922] , [Generator :: Loss : 2.6861588954925537]\n",
            "Epoch: 134 , [Discriminator :: Loss : 0.07320985943078995] , [Generator :: Loss : 3.033853530883789]\n",
            "Epoch: 135 , [Discriminator :: Loss : 0.020152706652879715] , [Generator :: Loss : 2.4840893745422363]\n",
            "Epoch: 136 , [Discriminator :: Loss : 0.008164908736944199] , [Generator :: Loss : 2.565657615661621]\n",
            "Epoch: 137 , [Discriminator :: Loss : 0.06255316734313965] , [Generator :: Loss : 3.7485663890838623]\n",
            "Epoch: 138 , [Discriminator :: Loss : 0.12249922007322311] , [Generator :: Loss : 2.73260235786438]\n",
            "Epoch: 139 , [Discriminator :: Loss : 0.27571773529052734] , [Generator :: Loss : 3.140183448791504]\n",
            "Epoch: 140 , [Discriminator :: Loss : 0.018155241385102272] , [Generator :: Loss : 3.6495370864868164]\n",
            "Epoch: 141 , [Discriminator :: Loss : 0.022106796503067017] , [Generator :: Loss : 3.9619927406311035]\n",
            "Epoch: 142 , [Discriminator :: Loss : 0.03293730691075325] , [Generator :: Loss : 5.0943450927734375]\n",
            "Epoch: 143 , [Discriminator :: Loss : 0.03439485654234886] , [Generator :: Loss : 4.708284378051758]\n",
            "Epoch: 144 , [Discriminator :: Loss : 0.11560772359371185] , [Generator :: Loss : 5.334780216217041]\n",
            "Epoch: 145 , [Discriminator :: Loss : 0.04062457010149956] , [Generator :: Loss : 4.087946891784668]\n",
            "Epoch: 146 , [Discriminator :: Loss : 0.03969094157218933] , [Generator :: Loss : 4.639880657196045]\n",
            "Epoch: 147 , [Discriminator :: Loss : 0.3768342137336731] , [Generator :: Loss : 5.2825846672058105]\n",
            "Epoch: 148 , [Discriminator :: Loss : 0.11537723243236542] , [Generator :: Loss : 4.649502277374268]\n",
            "Epoch: 149 , [Discriminator :: Loss : 0.04249639809131622] , [Generator :: Loss : 4.189258575439453]\n",
            "Epoch: 150 , [Discriminator :: Loss : 0.29413414001464844] , [Generator :: Loss : 3.520941734313965]\n",
            "Epoch: 151 , [Discriminator :: Loss : 0.09669756889343262] , [Generator :: Loss : 4.54208517074585]\n",
            "Epoch: 152 , [Discriminator :: Loss : 0.05318067595362663] , [Generator :: Loss : 4.17777156829834]\n",
            "Epoch: 153 , [Discriminator :: Loss : 0.05198284983634949] , [Generator :: Loss : 3.6615829467773438]\n",
            "Epoch: 154 , [Discriminator :: Loss : 0.121889628469944] , [Generator :: Loss : 4.757594108581543]\n",
            "Epoch: 155 , [Discriminator :: Loss : 0.003646210767328739] , [Generator :: Loss : 3.681973934173584]\n",
            "Epoch: 156 , [Discriminator :: Loss : 0.14733465015888214] , [Generator :: Loss : 3.823657512664795]\n",
            "Epoch: 157 , [Discriminator :: Loss : 0.017352432012557983] , [Generator :: Loss : 4.873201847076416]\n",
            "Epoch: 158 , [Discriminator :: Loss : 0.23335909843444824] , [Generator :: Loss : 5.046355247497559]\n",
            "Epoch: 159 , [Discriminator :: Loss : 0.08334463834762573] , [Generator :: Loss : 5.922954559326172]\n",
            "Epoch: 160 , [Discriminator :: Loss : 0.10201723128557205] , [Generator :: Loss : 5.844200611114502]\n",
            "Epoch: 161 , [Discriminator :: Loss : 0.10530335456132889] , [Generator :: Loss : 5.522911548614502]\n",
            "Epoch: 162 , [Discriminator :: Loss : 0.05082765966653824] , [Generator :: Loss : 5.692992210388184]\n",
            "Epoch: 163 , [Discriminator :: Loss : 0.040853917598724365] , [Generator :: Loss : 4.6935577392578125]\n",
            "Epoch: 164 , [Discriminator :: Loss : 0.02707490883767605] , [Generator :: Loss : 5.301819801330566]\n",
            "Epoch: 165 , [Discriminator :: Loss : 0.24343082308769226] , [Generator :: Loss : 3.637028217315674]\n",
            "Epoch: 166 , [Discriminator :: Loss : 0.005263861268758774] , [Generator :: Loss : 3.7213776111602783]\n",
            "Epoch: 167 , [Discriminator :: Loss : 0.0045120008289813995] , [Generator :: Loss : 3.462822437286377]\n",
            "Epoch: 168 , [Discriminator :: Loss : 0.024821363389492035] , [Generator :: Loss : 3.295851230621338]\n",
            "Epoch: 169 , [Discriminator :: Loss : 0.3168126046657562] , [Generator :: Loss : 3.906442642211914]\n",
            "Epoch: 170 , [Discriminator :: Loss : 0.0019231424666941166] , [Generator :: Loss : 3.9149723052978516]\n",
            "Epoch: 171 , [Discriminator :: Loss : 0.009449368342757225] , [Generator :: Loss : 3.9994583129882812]\n",
            "Epoch: 172 , [Discriminator :: Loss : 0.4009181261062622] , [Generator :: Loss : 4.969527244567871]\n",
            "Epoch: 173 , [Discriminator :: Loss : 0.07469271123409271] , [Generator :: Loss : 5.342211723327637]\n",
            "Epoch: 174 , [Discriminator :: Loss : 0.1884848177433014] , [Generator :: Loss : 6.70474910736084]\n",
            "Epoch: 175 , [Discriminator :: Loss : 0.05687374994158745] , [Generator :: Loss : 7.949609756469727]\n",
            "Epoch: 176 , [Discriminator :: Loss : 0.08296597748994827] , [Generator :: Loss : 6.082849502563477]\n",
            "Epoch: 177 , [Discriminator :: Loss : 0.325197696685791] , [Generator :: Loss : 4.39473819732666]\n",
            "Epoch: 178 , [Discriminator :: Loss : 0.043368835002183914] , [Generator :: Loss : 3.6507568359375]\n",
            "Epoch: 179 , [Discriminator :: Loss : 0.2035757303237915] , [Generator :: Loss : 2.4578142166137695]\n",
            "Epoch: 180 , [Discriminator :: Loss : 0.00801568478345871] , [Generator :: Loss : 1.8552844524383545]\n",
            "Epoch: 181 , [Discriminator :: Loss : 0.17649732530117035] , [Generator :: Loss : 1.5340590476989746]\n",
            "Epoch: 182 , [Discriminator :: Loss : 1.58231782913208] , [Generator :: Loss : 1.3744118213653564]\n",
            "Epoch: 183 , [Discriminator :: Loss : 0.0013484094524756074] , [Generator :: Loss : 1.8586199283599854]\n",
            "Epoch: 184 , [Discriminator :: Loss : 0.14154697954654694] , [Generator :: Loss : 1.0994657278060913]\n",
            "Epoch: 185 , [Discriminator :: Loss : 0.0003696434432640672] , [Generator :: Loss : 3.3505125045776367]\n",
            "Epoch: 186 , [Discriminator :: Loss : 1.5549664497375488] , [Generator :: Loss : 3.5896928310394287]\n",
            "Epoch: 187 , [Discriminator :: Loss : 0.0899515450000763] , [Generator :: Loss : 6.490776538848877]\n",
            "Epoch: 188 , [Discriminator :: Loss : 0.01483688410371542] , [Generator :: Loss : 6.7170915603637695]\n",
            "Epoch: 189 , [Discriminator :: Loss : 0.01620921865105629] , [Generator :: Loss : 7.747386455535889]\n",
            "Epoch: 190 , [Discriminator :: Loss : 0.14144869148731232] , [Generator :: Loss : 8.674135208129883]\n",
            "Epoch: 191 , [Discriminator :: Loss : 0.28828710317611694] , [Generator :: Loss : 7.916281223297119]\n",
            "Epoch: 192 , [Discriminator :: Loss : 0.07822269946336746] , [Generator :: Loss : 8.770379066467285]\n",
            "Epoch: 193 , [Discriminator :: Loss : 0.18193814158439636] , [Generator :: Loss : 5.711305618286133]\n",
            "Epoch: 194 , [Discriminator :: Loss : 0.05113775655627251] , [Generator :: Loss : 4.073223114013672]\n",
            "Epoch: 195 , [Discriminator :: Loss : 0.009008456952869892] , [Generator :: Loss : 4.864975452423096]\n",
            "Epoch: 196 , [Discriminator :: Loss : 0.001847588922828436] , [Generator :: Loss : 4.255983352661133]\n",
            "Epoch: 197 , [Discriminator :: Loss : 0.17256885766983032] , [Generator :: Loss : 4.217880725860596]\n",
            "Epoch: 198 , [Discriminator :: Loss : 0.048204611986875534] , [Generator :: Loss : 2.391465187072754]\n",
            "Epoch: 199 , [Discriminator :: Loss : 0.000569333671592176] , [Generator :: Loss : 3.7909090518951416]\n",
            "Epoch: 200 , [Discriminator :: Loss : 0.03386395797133446] , [Generator :: Loss : 2.5341105461120605]\n",
            "Epoch: 201 , [Discriminator :: Loss : 0.5108709931373596] , [Generator :: Loss : 2.4990427494049072]\n",
            "Epoch: 202 , [Discriminator :: Loss : 0.036095283925533295] , [Generator :: Loss : 3.7185750007629395]\n",
            "Epoch: 203 , [Discriminator :: Loss : 0.21405719220638275] , [Generator :: Loss : 4.057934284210205]\n",
            "Epoch: 204 , [Discriminator :: Loss : 0.20084227621555328] , [Generator :: Loss : 3.973529815673828]\n",
            "Epoch: 205 , [Discriminator :: Loss : 0.12618273496627808] , [Generator :: Loss : 5.1671905517578125]\n",
            "Epoch: 206 , [Discriminator :: Loss : 0.051663950085639954] , [Generator :: Loss : 6.120907306671143]\n",
            "Epoch: 207 , [Discriminator :: Loss : 0.052222806960344315] , [Generator :: Loss : 7.80980110168457]\n",
            "Epoch: 208 , [Discriminator :: Loss : 0.4748198986053467] , [Generator :: Loss : 7.89739990234375]\n",
            "Epoch: 209 , [Discriminator :: Loss : 0.26172155141830444] , [Generator :: Loss : 6.451530933380127]\n",
            "Epoch: 210 , [Discriminator :: Loss : 0.05364753305912018] , [Generator :: Loss : 6.6749796867370605]\n",
            "Epoch: 211 , [Discriminator :: Loss : 0.021657811477780342] , [Generator :: Loss : 4.704352378845215]\n",
            "Epoch: 212 , [Discriminator :: Loss : 0.07021869719028473] , [Generator :: Loss : 3.5989198684692383]\n",
            "Epoch: 213 , [Discriminator :: Loss : 0.01110732089728117] , [Generator :: Loss : 4.656078338623047]\n",
            "Epoch: 214 , [Discriminator :: Loss : 0.013832987286150455] , [Generator :: Loss : 3.0675954818725586]\n",
            "Epoch: 215 , [Discriminator :: Loss : 0.008616451174020767] , [Generator :: Loss : 2.489542007446289]\n",
            "Epoch: 216 , [Discriminator :: Loss : 0.0021087226923555136] , [Generator :: Loss : 2.151766300201416]\n",
            "Epoch: 217 , [Discriminator :: Loss : 0.844620943069458] , [Generator :: Loss : 2.0672378540039062]\n",
            "Epoch: 218 , [Discriminator :: Loss : 0.04280416667461395] , [Generator :: Loss : 2.2108120918273926]\n",
            "Epoch: 219 , [Discriminator :: Loss : 0.40782976150512695] , [Generator :: Loss : 2.7021000385284424]\n",
            "Epoch: 220 , [Discriminator :: Loss : 0.22269117832183838] , [Generator :: Loss : 3.3035683631896973]\n",
            "Epoch: 221 , [Discriminator :: Loss : 0.00411166762933135] , [Generator :: Loss : 4.36695671081543]\n",
            "Epoch: 222 , [Discriminator :: Loss : 0.05782060697674751] , [Generator :: Loss : 4.486120223999023]\n",
            "Epoch: 223 , [Discriminator :: Loss : 0.25713154673576355] , [Generator :: Loss : 5.811914443969727]\n",
            "Epoch: 224 , [Discriminator :: Loss : 0.5794923305511475] , [Generator :: Loss : 3.67950439453125]\n",
            "Epoch: 225 , [Discriminator :: Loss : 0.15584997832775116] , [Generator :: Loss : 3.6235294342041016]\n",
            "Epoch: 226 , [Discriminator :: Loss : 0.1709711253643036] , [Generator :: Loss : 3.8527355194091797]\n",
            "Epoch: 227 , [Discriminator :: Loss : 0.010676774196326733] , [Generator :: Loss : 3.302849292755127]\n",
            "Epoch: 228 , [Discriminator :: Loss : 0.012127536348998547] , [Generator :: Loss : 3.0590250492095947]\n",
            "Epoch: 229 , [Discriminator :: Loss : 0.23552188277244568] , [Generator :: Loss : 3.551032781600952]\n",
            "Epoch: 230 , [Discriminator :: Loss : 0.13072852790355682] , [Generator :: Loss : 2.9748470783233643]\n",
            "Epoch: 231 , [Discriminator :: Loss : 0.21321289241313934] , [Generator :: Loss : 3.5145444869995117]\n",
            "Epoch: 232 , [Discriminator :: Loss : 0.0073845223523676395] , [Generator :: Loss : 4.366790294647217]\n",
            "Epoch: 233 , [Discriminator :: Loss : 0.2656307518482208] , [Generator :: Loss : 6.1667280197143555]\n",
            "Epoch: 234 , [Discriminator :: Loss : 0.07853314280509949] , [Generator :: Loss : 6.303160667419434]\n",
            "Epoch: 235 , [Discriminator :: Loss : 0.22153040766716003] , [Generator :: Loss : 6.292264461517334]\n",
            "Epoch: 236 , [Discriminator :: Loss : 0.3628164231777191] , [Generator :: Loss : 6.49211311340332]\n",
            "Epoch: 237 , [Discriminator :: Loss : 0.6963577270507812] , [Generator :: Loss : 4.818523406982422]\n",
            "Epoch: 238 , [Discriminator :: Loss : 0.39882737398147583] , [Generator :: Loss : 5.900847911834717]\n",
            "Epoch: 239 , [Discriminator :: Loss : 0.030089931562542915] , [Generator :: Loss : 4.567656517028809]\n",
            "Epoch: 240 , [Discriminator :: Loss : 0.41317039728164673] , [Generator :: Loss : 5.040137767791748]\n",
            "Epoch: 241 , [Discriminator :: Loss : 0.07059141248464584] , [Generator :: Loss : 5.80850887298584]\n",
            "Epoch: 242 , [Discriminator :: Loss : 0.2534681558609009] , [Generator :: Loss : 5.175273895263672]\n",
            "Epoch: 243 , [Discriminator :: Loss : 0.18243193626403809] , [Generator :: Loss : 3.7380285263061523]\n",
            "Epoch: 244 , [Discriminator :: Loss : 0.12649449706077576] , [Generator :: Loss : 3.6486682891845703]\n",
            "Epoch: 245 , [Discriminator :: Loss : 1.2903074026107788] , [Generator :: Loss : 3.280510663986206]\n",
            "Epoch: 246 , [Discriminator :: Loss : 0.31688159704208374] , [Generator :: Loss : 4.705380439758301]\n",
            "Epoch: 247 , [Discriminator :: Loss : 0.07362915575504303] , [Generator :: Loss : 5.1156206130981445]\n",
            "Epoch: 248 , [Discriminator :: Loss : 0.07776307314634323] , [Generator :: Loss : 7.084383964538574]\n",
            "Epoch: 249 , [Discriminator :: Loss : 0.1413601189851761] , [Generator :: Loss : 6.478457450866699]\n",
            "Epoch: 250 , [Discriminator :: Loss : 0.11487928032875061] , [Generator :: Loss : 6.017248630523682]\n",
            "Epoch: 251 , [Discriminator :: Loss : 0.14618483185768127] , [Generator :: Loss : 6.010710716247559]\n",
            "Epoch: 252 , [Discriminator :: Loss : 0.10050462931394577] , [Generator :: Loss : 4.465323448181152]\n",
            "Epoch: 253 , [Discriminator :: Loss : 0.33647212386131287] , [Generator :: Loss : 2.8016836643218994]\n",
            "Epoch: 254 , [Discriminator :: Loss : 0.10307634621858597] , [Generator :: Loss : 2.071882724761963]\n",
            "Epoch: 255 , [Discriminator :: Loss : 0.13340675830841064] , [Generator :: Loss : 2.2226529121398926]\n",
            "Epoch: 256 , [Discriminator :: Loss : 0.15702106058597565] , [Generator :: Loss : 1.6514606475830078]\n",
            "Epoch: 257 , [Discriminator :: Loss : 0.006311597302556038] , [Generator :: Loss : 1.6537797451019287]\n",
            "Epoch: 258 , [Discriminator :: Loss : 0.0974854975938797] , [Generator :: Loss : 2.5478427410125732]\n",
            "Epoch: 259 , [Discriminator :: Loss : 0.020684249699115753] , [Generator :: Loss : 2.870093584060669]\n",
            "Epoch: 260 , [Discriminator :: Loss : 0.11425907164812088] , [Generator :: Loss : 3.370988368988037]\n",
            "Epoch: 261 , [Discriminator :: Loss : 0.0418533980846405] , [Generator :: Loss : 4.164880752563477]\n",
            "Epoch: 262 , [Discriminator :: Loss : 0.10370946675539017] , [Generator :: Loss : 4.8002729415893555]\n",
            "Epoch: 263 , [Discriminator :: Loss : 0.22496813535690308] , [Generator :: Loss : 7.362837791442871]\n",
            "Epoch: 264 , [Discriminator :: Loss : 0.19899778068065643] , [Generator :: Loss : 6.436162948608398]\n",
            "Epoch: 265 , [Discriminator :: Loss : 0.10316190868616104] , [Generator :: Loss : 7.348408222198486]\n",
            "Epoch: 266 , [Discriminator :: Loss : 0.5302742719650269] , [Generator :: Loss : 6.673137664794922]\n",
            "Epoch: 267 , [Discriminator :: Loss : 0.11110321432352066] , [Generator :: Loss : 4.824554920196533]\n",
            "Epoch: 268 , [Discriminator :: Loss : 0.06383141875267029] , [Generator :: Loss : 2.9377899169921875]\n",
            "Epoch: 269 , [Discriminator :: Loss : 0.09177972376346588] , [Generator :: Loss : 1.8289783000946045]\n",
            "Epoch: 270 , [Discriminator :: Loss : 0.533758819103241] , [Generator :: Loss : 2.4747440814971924]\n",
            "Epoch: 271 , [Discriminator :: Loss : 0.018069308251142502] , [Generator :: Loss : 2.903334140777588]\n",
            "Epoch: 272 , [Discriminator :: Loss : 0.04103665426373482] , [Generator :: Loss : 3.568498373031616]\n",
            "Epoch: 273 , [Discriminator :: Loss : 0.011499302461743355] , [Generator :: Loss : 5.03610897064209]\n",
            "Epoch: 274 , [Discriminator :: Loss : 0.8957356810569763] , [Generator :: Loss : 6.630398750305176]\n",
            "Epoch: 275 , [Discriminator :: Loss : 0.3523758053779602] , [Generator :: Loss : 6.877280235290527]\n",
            "Epoch: 276 , [Discriminator :: Loss : 0.20127074420452118] , [Generator :: Loss : 6.15970516204834]\n",
            "Epoch: 277 , [Discriminator :: Loss : 1.312232494354248] , [Generator :: Loss : 3.9144599437713623]\n",
            "Epoch: 278 , [Discriminator :: Loss : 0.2493598312139511] , [Generator :: Loss : 3.6075546741485596]\n",
            "Epoch: 279 , [Discriminator :: Loss : 0.5110570192337036] , [Generator :: Loss : 3.7397241592407227]\n",
            "Epoch: 280 , [Discriminator :: Loss : 0.0776980072259903] , [Generator :: Loss : 2.78167724609375]\n",
            "Epoch: 281 , [Discriminator :: Loss : 0.040326397866010666] , [Generator :: Loss : 2.856721878051758]\n",
            "Epoch: 282 , [Discriminator :: Loss : 0.3201129734516144] , [Generator :: Loss : 2.8720343112945557]\n",
            "Epoch: 283 , [Discriminator :: Loss : 0.06798014044761658] , [Generator :: Loss : 2.6762726306915283]\n",
            "Epoch: 284 , [Discriminator :: Loss : 0.2054271697998047] , [Generator :: Loss : 2.724724531173706]\n",
            "Epoch: 285 , [Discriminator :: Loss : 0.050097476691007614] , [Generator :: Loss : 3.4247820377349854]\n",
            "Epoch: 286 , [Discriminator :: Loss : 0.03177293390035629] , [Generator :: Loss : 3.9986355304718018]\n",
            "Epoch: 287 , [Discriminator :: Loss : 0.004962784703820944] , [Generator :: Loss : 4.887119293212891]\n",
            "Epoch: 288 , [Discriminator :: Loss : 0.010398173704743385] , [Generator :: Loss : 4.1427388191223145]\n",
            "Epoch: 289 , [Discriminator :: Loss : 0.3267805576324463] , [Generator :: Loss : 4.223156929016113]\n",
            "Epoch: 290 , [Discriminator :: Loss : 0.01991141028702259] , [Generator :: Loss : 4.575344085693359]\n",
            "Epoch: 291 , [Discriminator :: Loss : 0.06931915879249573] , [Generator :: Loss : 5.678179740905762]\n",
            "Epoch: 292 , [Discriminator :: Loss : 0.19410796463489532] , [Generator :: Loss : 3.587212324142456]\n",
            "Epoch: 293 , [Discriminator :: Loss : 0.16567033529281616] , [Generator :: Loss : 2.5830419063568115]\n",
            "Epoch: 294 , [Discriminator :: Loss : 0.02890203334391117] , [Generator :: Loss : 2.8974993228912354]\n",
            "Epoch: 295 , [Discriminator :: Loss : 0.057983774691820145] , [Generator :: Loss : 2.003340244293213]\n",
            "Epoch: 296 , [Discriminator :: Loss : 0.1804932802915573] , [Generator :: Loss : 3.1493356227874756]\n",
            "Epoch: 297 , [Discriminator :: Loss : 0.10428878664970398] , [Generator :: Loss : 2.7174999713897705]\n",
            "Epoch: 298 , [Discriminator :: Loss : 0.7481427788734436] , [Generator :: Loss : 4.491363525390625]\n",
            "Epoch: 299 , [Discriminator :: Loss : 0.024614449590444565] , [Generator :: Loss : 5.369845867156982]\n",
            "Epoch: 300 , [Discriminator :: Loss : 1.1616933345794678] , [Generator :: Loss : 6.078711032867432]\n",
            "Epoch: 301 , [Discriminator :: Loss : 0.14214210212230682] , [Generator :: Loss : 6.609774589538574]\n",
            "Epoch: 302 , [Discriminator :: Loss : 0.19346515834331512] , [Generator :: Loss : 6.8822736740112305]\n",
            "Epoch: 303 , [Discriminator :: Loss : 0.019340351223945618] , [Generator :: Loss : 6.749227523803711]\n",
            "Epoch: 304 , [Discriminator :: Loss : 0.09333744645118713] , [Generator :: Loss : 5.937373638153076]\n",
            "Epoch: 305 , [Discriminator :: Loss : 0.0426793210208416] , [Generator :: Loss : 4.648048400878906]\n",
            "Epoch: 306 , [Discriminator :: Loss : 0.06576502323150635] , [Generator :: Loss : 3.059199094772339]\n",
            "Epoch: 307 , [Discriminator :: Loss : 0.05865989252924919] , [Generator :: Loss : 2.563744068145752]\n",
            "Epoch: 308 , [Discriminator :: Loss : 0.09738465398550034] , [Generator :: Loss : 2.0583391189575195]\n",
            "Epoch: 309 , [Discriminator :: Loss : 0.09414025396108627] , [Generator :: Loss : 2.7327804565429688]\n",
            "Epoch: 310 , [Discriminator :: Loss : 0.2821462154388428] , [Generator :: Loss : 2.694575786590576]\n",
            "Epoch: 311 , [Discriminator :: Loss : 0.07176290452480316] , [Generator :: Loss : 3.5554494857788086]\n",
            "Epoch: 312 , [Discriminator :: Loss : 0.03675716742873192] , [Generator :: Loss : 5.273462295532227]\n",
            "Epoch: 313 , [Discriminator :: Loss : 0.11367977410554886] , [Generator :: Loss : 6.28231954574585]\n",
            "Epoch: 314 , [Discriminator :: Loss : 0.3440733551979065] , [Generator :: Loss : 6.225924968719482]\n",
            "Epoch: 315 , [Discriminator :: Loss : 0.05380750447511673] , [Generator :: Loss : 5.33040714263916]\n",
            "Epoch: 316 , [Discriminator :: Loss : 0.12027403712272644] , [Generator :: Loss : 3.6787173748016357]\n",
            "Epoch: 317 , [Discriminator :: Loss : 0.017050229012966156] , [Generator :: Loss : 2.9470181465148926]\n",
            "Epoch: 318 , [Discriminator :: Loss : 0.034943945705890656] , [Generator :: Loss : 1.873175859451294]\n",
            "Epoch: 319 , [Discriminator :: Loss : 0.026836154982447624] , [Generator :: Loss : 0.8975160717964172]\n",
            "Epoch: 320 , [Discriminator :: Loss : 0.05910998955368996] , [Generator :: Loss : 1.0283174514770508]\n",
            "Epoch: 321 , [Discriminator :: Loss : 1.3148479461669922] , [Generator :: Loss : 1.5225595235824585]\n",
            "Epoch: 322 , [Discriminator :: Loss : 0.029022708535194397] , [Generator :: Loss : 3.7370896339416504]\n",
            "Epoch: 323 , [Discriminator :: Loss : 0.014401501975953579] , [Generator :: Loss : 3.6452600955963135]\n",
            "Epoch: 324 , [Discriminator :: Loss : 0.19322200119495392] , [Generator :: Loss : 5.284214496612549]\n",
            "Epoch: 325 , [Discriminator :: Loss : 0.8069800138473511] , [Generator :: Loss : 5.03733491897583]\n",
            "Epoch: 326 , [Discriminator :: Loss : 0.3985966444015503] , [Generator :: Loss : 2.264747142791748]\n",
            "Epoch: 327 , [Discriminator :: Loss : 0.10907826572656631] , [Generator :: Loss : 1.1317503452301025]\n",
            "Epoch: 328 , [Discriminator :: Loss : 0.1292019784450531] , [Generator :: Loss : 1.081559419631958]\n",
            "Epoch: 329 , [Discriminator :: Loss : 0.24722513556480408] , [Generator :: Loss : 1.150936484336853]\n",
            "Epoch: 330 , [Discriminator :: Loss : 0.1963379830121994] , [Generator :: Loss : 1.4904004335403442]\n",
            "Epoch: 331 , [Discriminator :: Loss : 0.07130017876625061] , [Generator :: Loss : 2.6034741401672363]\n",
            "Epoch: 332 , [Discriminator :: Loss : 0.04824165254831314] , [Generator :: Loss : 3.1133100986480713]\n",
            "Epoch: 333 , [Discriminator :: Loss : 0.5333210229873657] , [Generator :: Loss : 4.64148473739624]\n",
            "Epoch: 334 , [Discriminator :: Loss : 0.06753203272819519] , [Generator :: Loss : 6.315009117126465]\n",
            "Epoch: 335 , [Discriminator :: Loss : 0.16549856960773468] , [Generator :: Loss : 6.258318901062012]\n",
            "Epoch: 336 , [Discriminator :: Loss : 0.02744370698928833] , [Generator :: Loss : 7.013839244842529]\n",
            "Epoch: 337 , [Discriminator :: Loss : 0.15705446898937225] , [Generator :: Loss : 6.702673435211182]\n",
            "Epoch: 338 , [Discriminator :: Loss : 0.1538795679807663] , [Generator :: Loss : 6.799978733062744]\n",
            "Epoch: 339 , [Discriminator :: Loss : 0.2071869969367981] , [Generator :: Loss : 5.19789981842041]\n",
            "Epoch: 340 , [Discriminator :: Loss : 0.23744286596775055] , [Generator :: Loss : 5.10283088684082]\n",
            "Epoch: 341 , [Discriminator :: Loss : 0.08109258115291595] , [Generator :: Loss : 2.6474344730377197]\n",
            "Epoch: 342 , [Discriminator :: Loss : 0.257388174533844] , [Generator :: Loss : 2.335580348968506]\n",
            "Epoch: 343 , [Discriminator :: Loss : 0.007736758328974247] , [Generator :: Loss : 2.6008520126342773]\n",
            "Epoch: 344 , [Discriminator :: Loss : 1.0444540977478027] , [Generator :: Loss : 1.7015323638916016]\n",
            "Epoch: 345 , [Discriminator :: Loss : 0.48770707845687866] , [Generator :: Loss : 2.7147860527038574]\n",
            "Epoch: 346 , [Discriminator :: Loss : 0.018349796533584595] , [Generator :: Loss : 3.808981418609619]\n",
            "Epoch: 347 , [Discriminator :: Loss : 0.03513076528906822] , [Generator :: Loss : 5.480907917022705]\n",
            "Epoch: 348 , [Discriminator :: Loss : 0.5637953281402588] , [Generator :: Loss : 6.853604316711426]\n",
            "Epoch: 349 , [Discriminator :: Loss : 0.03130047023296356] , [Generator :: Loss : 7.869381904602051]\n",
            "Epoch: 350 , [Discriminator :: Loss : 0.04016765579581261] , [Generator :: Loss : 9.857368469238281]\n",
            "Epoch: 351 , [Discriminator :: Loss : 0.5475491881370544] , [Generator :: Loss : 7.555727958679199]\n",
            "Epoch: 352 , [Discriminator :: Loss : 0.3403555750846863] , [Generator :: Loss : 6.044740200042725]\n",
            "Epoch: 353 , [Discriminator :: Loss : 0.4936804175376892] , [Generator :: Loss : 4.136183738708496]\n",
            "Epoch: 354 , [Discriminator :: Loss : 0.012841654941439629] , [Generator :: Loss : 2.4940896034240723]\n",
            "Epoch: 355 , [Discriminator :: Loss : 0.017294926568865776] , [Generator :: Loss : 1.0640523433685303]\n",
            "Epoch: 356 , [Discriminator :: Loss : 0.07509920746088028] , [Generator :: Loss : 0.3303343951702118]\n",
            "Epoch: 357 , [Discriminator :: Loss : 1.4332919120788574] , [Generator :: Loss : 0.3130422830581665]\n",
            "Epoch: 358 , [Discriminator :: Loss : 0.44289612770080566] , [Generator :: Loss : 0.9771469235420227]\n",
            "Epoch: 359 , [Discriminator :: Loss : 0.07843764126300812] , [Generator :: Loss : 4.079477787017822]\n",
            "Epoch: 360 , [Discriminator :: Loss : 0.009020108729600906] , [Generator :: Loss : 4.170263290405273]\n",
            "Epoch: 361 , [Discriminator :: Loss : 0.052997250109910965] , [Generator :: Loss : 5.596465110778809]\n",
            "Epoch: 362 , [Discriminator :: Loss : 0.1484852433204651] , [Generator :: Loss : 6.0805511474609375]\n",
            "Epoch: 363 , [Discriminator :: Loss : 0.051423124969005585] , [Generator :: Loss : 8.024280548095703]\n",
            "Epoch: 364 , [Discriminator :: Loss : 0.034816984087228775] , [Generator :: Loss : 7.791077613830566]\n",
            "Epoch: 365 , [Discriminator :: Loss : 0.1394234448671341] , [Generator :: Loss : 6.898678779602051]\n",
            "Epoch: 366 , [Discriminator :: Loss : 0.5398842096328735] , [Generator :: Loss : 5.91823673248291]\n",
            "Epoch: 367 , [Discriminator :: Loss : 0.5398980975151062] , [Generator :: Loss : 3.5056028366088867]\n",
            "Epoch: 368 , [Discriminator :: Loss : 0.0506146065890789] , [Generator :: Loss : 1.8002842664718628]\n",
            "Epoch: 369 , [Discriminator :: Loss : 0.003859354183077812] , [Generator :: Loss : 1.1425871849060059]\n",
            "Epoch: 370 , [Discriminator :: Loss : 0.12526242434978485] , [Generator :: Loss : 0.5829105377197266]\n",
            "Epoch: 371 , [Discriminator :: Loss : 0.061201225966215134] , [Generator :: Loss : 0.3094435930252075]\n",
            "Epoch: 372 , [Discriminator :: Loss : 0.9993607997894287] , [Generator :: Loss : 0.3827369511127472]\n",
            "Epoch: 373 , [Discriminator :: Loss : 0.3051328659057617] , [Generator :: Loss : 0.415517121553421]\n",
            "Epoch: 374 , [Discriminator :: Loss : 1.6860584020614624] , [Generator :: Loss : 1.0980252027511597]\n",
            "Epoch: 375 , [Discriminator :: Loss : 1.1696416139602661] , [Generator :: Loss : 3.0271997451782227]\n",
            "Epoch: 376 , [Discriminator :: Loss : 0.01765359193086624] , [Generator :: Loss : 5.725286483764648]\n",
            "Epoch: 377 , [Discriminator :: Loss : 0.013104435987770557] , [Generator :: Loss : 6.333859920501709]\n",
            "Epoch: 378 , [Discriminator :: Loss : 0.3164447247982025] , [Generator :: Loss : 9.228392601013184]\n",
            "Epoch: 379 , [Discriminator :: Loss : 0.23619423806667328] , [Generator :: Loss : 7.828857421875]\n",
            "Epoch: 380 , [Discriminator :: Loss : 0.3236571252346039] , [Generator :: Loss : 8.799269676208496]\n",
            "Epoch: 381 , [Discriminator :: Loss : 0.22930453717708588] , [Generator :: Loss : 7.40430212020874]\n",
            "Epoch: 382 , [Discriminator :: Loss : 0.22125349938869476] , [Generator :: Loss : 6.740207195281982]\n",
            "Epoch: 383 , [Discriminator :: Loss : 0.056428030133247375] , [Generator :: Loss : 5.00419807434082]\n",
            "Epoch: 384 , [Discriminator :: Loss : 0.02657932974398136] , [Generator :: Loss : 3.278693914413452]\n",
            "Epoch: 385 , [Discriminator :: Loss : 0.3870064318180084] , [Generator :: Loss : 4.733043670654297]\n",
            "Epoch: 386 , [Discriminator :: Loss : 0.05042928084731102] , [Generator :: Loss : 3.27665376663208]\n",
            "Epoch: 387 , [Discriminator :: Loss : 0.14927969872951508] , [Generator :: Loss : 1.8049461841583252]\n",
            "Epoch: 388 , [Discriminator :: Loss : 0.19094064831733704] , [Generator :: Loss : 3.552192449569702]\n",
            "Epoch: 389 , [Discriminator :: Loss : 0.04114130511879921] , [Generator :: Loss : 3.0132200717926025]\n",
            "Epoch: 390 , [Discriminator :: Loss : 0.08247451484203339] , [Generator :: Loss : 2.4901466369628906]\n",
            "Epoch: 391 , [Discriminator :: Loss : 0.07214074581861496] , [Generator :: Loss : 3.8244967460632324]\n",
            "Epoch: 392 , [Discriminator :: Loss : 0.029074396938085556] , [Generator :: Loss : 4.80246114730835]\n",
            "Epoch: 393 , [Discriminator :: Loss : 0.01596703752875328] , [Generator :: Loss : 4.059162616729736]\n",
            "Epoch: 394 , [Discriminator :: Loss : 0.06267481297254562] , [Generator :: Loss : 4.477015495300293]\n",
            "Epoch: 395 , [Discriminator :: Loss : 0.051345739513635635] , [Generator :: Loss : 4.162139415740967]\n",
            "Epoch: 396 , [Discriminator :: Loss : 0.0529126413166523] , [Generator :: Loss : 3.43410325050354]\n",
            "Epoch: 397 , [Discriminator :: Loss : 0.0595470629632473] , [Generator :: Loss : 3.768298625946045]\n",
            "Epoch: 398 , [Discriminator :: Loss : 0.10956208407878876] , [Generator :: Loss : 3.7421860694885254]\n",
            "Epoch: 399 , [Discriminator :: Loss : 0.11017358303070068] , [Generator :: Loss : 3.5049922466278076]\n",
            "Epoch: 400 , [Discriminator :: Loss : 0.05560651421546936] , [Generator :: Loss : 3.263594150543213]\n",
            "Epoch: 401 , [Discriminator :: Loss : 0.946577787399292] , [Generator :: Loss : 2.8660295009613037]\n",
            "Epoch: 402 , [Discriminator :: Loss : 0.0313245914876461] , [Generator :: Loss : 9.958385467529297]\n",
            "Epoch: 403 , [Discriminator :: Loss : 0.07296738028526306] , [Generator :: Loss : 2.7502877712249756]\n",
            "Epoch: 404 , [Discriminator :: Loss : 0.1524587869644165] , [Generator :: Loss : 2.884343147277832]\n",
            "Epoch: 405 , [Discriminator :: Loss : 0.051513656973838806] , [Generator :: Loss : 3.888883113861084]\n",
            "Epoch: 406 , [Discriminator :: Loss : 0.03808321803808212] , [Generator :: Loss : 3.1909890174865723]\n",
            "Epoch: 407 , [Discriminator :: Loss : 0.07806435972452164] , [Generator :: Loss : 3.274200916290283]\n",
            "Epoch: 408 , [Discriminator :: Loss : 0.24614016711711884] , [Generator :: Loss : 2.8912978172302246]\n",
            "Epoch: 409 , [Discriminator :: Loss : 0.3664948344230652] , [Generator :: Loss : 2.641669511795044]\n",
            "Epoch: 410 , [Discriminator :: Loss : 0.17343756556510925] , [Generator :: Loss : 3.7287795543670654]\n",
            "Epoch: 411 , [Discriminator :: Loss : 0.04745689406991005] , [Generator :: Loss : 5.005977630615234]\n",
            "Epoch: 412 , [Discriminator :: Loss : 0.056826990097761154] , [Generator :: Loss : 4.392024993896484]\n",
            "Epoch: 413 , [Discriminator :: Loss : 0.14408794045448303] , [Generator :: Loss : 4.369947910308838]\n",
            "Epoch: 414 , [Discriminator :: Loss : 0.4901321828365326] , [Generator :: Loss : 3.9168801307678223]\n",
            "Epoch: 415 , [Discriminator :: Loss : 0.03618986904621124] , [Generator :: Loss : 3.4123990535736084]\n",
            "Epoch: 416 , [Discriminator :: Loss : 0.04409337416291237] , [Generator :: Loss : 1.8270180225372314]\n",
            "Epoch: 417 , [Discriminator :: Loss : 0.029454587027430534] , [Generator :: Loss : 1.3648080825805664]\n",
            "Epoch: 418 , [Discriminator :: Loss : 0.38619956374168396] , [Generator :: Loss : 1.7528408765792847]\n",
            "Epoch: 419 , [Discriminator :: Loss : 0.05646751821041107] , [Generator :: Loss : 1.8069334030151367]\n",
            "Epoch: 420 , [Discriminator :: Loss : 0.31715500354766846] , [Generator :: Loss : 3.5099120140075684]\n",
            "Epoch: 421 , [Discriminator :: Loss : 0.06300323456525803] , [Generator :: Loss : 4.407301902770996]\n",
            "Epoch: 422 , [Discriminator :: Loss : 0.019070196896791458] , [Generator :: Loss : 6.645126819610596]\n",
            "Epoch: 423 , [Discriminator :: Loss : 0.044687848538160324] , [Generator :: Loss : 6.694395542144775]\n",
            "Epoch: 424 , [Discriminator :: Loss : 0.3180895447731018] , [Generator :: Loss : 6.045894145965576]\n",
            "Epoch: 425 , [Discriminator :: Loss : 0.46840229630470276] , [Generator :: Loss : 4.832237243652344]\n",
            "Epoch: 426 , [Discriminator :: Loss : 0.12339039146900177] , [Generator :: Loss : 4.052870750427246]\n",
            "Epoch: 427 , [Discriminator :: Loss : 0.07883843779563904] , [Generator :: Loss : 3.269963026046753]\n",
            "Epoch: 428 , [Discriminator :: Loss : 0.3747228682041168] , [Generator :: Loss : 1.758615255355835]\n",
            "Epoch: 429 , [Discriminator :: Loss : 0.38455602526664734] , [Generator :: Loss : 3.957944393157959]\n",
            "Epoch: 430 , [Discriminator :: Loss : 0.3083636462688446] , [Generator :: Loss : 3.389967441558838]\n",
            "Epoch: 431 , [Discriminator :: Loss : 0.4202191233634949] , [Generator :: Loss : 5.181077480316162]\n",
            "Epoch: 432 , [Discriminator :: Loss : 0.10706028342247009] , [Generator :: Loss : 5.727949142456055]\n",
            "Epoch: 433 , [Discriminator :: Loss : 0.18534645438194275] , [Generator :: Loss : 7.174692630767822]\n",
            "Epoch: 434 , [Discriminator :: Loss : 0.11453402042388916] , [Generator :: Loss : 8.39702033996582]\n",
            "Epoch: 435 , [Discriminator :: Loss : 0.0655612125992775] , [Generator :: Loss : 8.39472484588623]\n",
            "Epoch: 436 , [Discriminator :: Loss : 0.7337285876274109] , [Generator :: Loss : 7.115234375]\n",
            "Epoch: 437 , [Discriminator :: Loss : 0.2648278474807739] , [Generator :: Loss : 5.465399742126465]\n",
            "Epoch: 438 , [Discriminator :: Loss : 0.012750748544931412] , [Generator :: Loss : 3.9465246200561523]\n",
            "Epoch: 439 , [Discriminator :: Loss : 0.027993377298116684] , [Generator :: Loss : 2.1533544063568115]\n",
            "Epoch: 440 , [Discriminator :: Loss : 0.38494592905044556] , [Generator :: Loss : 2.375619888305664]\n",
            "Epoch: 441 , [Discriminator :: Loss : 0.7583580017089844] , [Generator :: Loss : 2.4420340061187744]\n",
            "Epoch: 442 , [Discriminator :: Loss : 0.007271549664437771] , [Generator :: Loss : 3.3155927658081055]\n",
            "Epoch: 443 , [Discriminator :: Loss : 0.03298579901456833] , [Generator :: Loss : 4.432748794555664]\n",
            "Epoch: 444 , [Discriminator :: Loss : 0.4158318042755127] , [Generator :: Loss : 4.450772285461426]\n",
            "Epoch: 445 , [Discriminator :: Loss : 0.014433087781071663] , [Generator :: Loss : 7.165373802185059]\n",
            "Epoch: 446 , [Discriminator :: Loss : 0.021460188552737236] , [Generator :: Loss : 6.44287109375]\n",
            "Epoch: 447 , [Discriminator :: Loss : 0.013239671476185322] , [Generator :: Loss : 7.966889381408691]\n",
            "Epoch: 448 , [Discriminator :: Loss : 0.23856878280639648] , [Generator :: Loss : 7.270202159881592]\n",
            "Epoch: 449 , [Discriminator :: Loss : 0.027323072776198387] , [Generator :: Loss : 7.709623336791992]\n",
            "Epoch: 450 , [Discriminator :: Loss : 0.02347422018647194] , [Generator :: Loss : 7.43619441986084]\n",
            "Epoch: 451 , [Discriminator :: Loss : 0.03013564459979534] , [Generator :: Loss : 7.34991455078125]\n",
            "Epoch: 452 , [Discriminator :: Loss : 0.050206758081912994] , [Generator :: Loss : 8.294024467468262]\n",
            "Epoch: 453 , [Discriminator :: Loss : 0.04254729673266411] , [Generator :: Loss : 6.6538848876953125]\n",
            "Epoch: 454 , [Discriminator :: Loss : 0.03848656266927719] , [Generator :: Loss : 6.037242889404297]\n",
            "Epoch: 455 , [Discriminator :: Loss : 0.028572291135787964] , [Generator :: Loss : 5.3486328125]\n",
            "Epoch: 456 , [Discriminator :: Loss : 0.02551908977329731] , [Generator :: Loss : 4.8485798835754395]\n",
            "Epoch: 457 , [Discriminator :: Loss : 0.03501516580581665] , [Generator :: Loss : 4.485844612121582]\n",
            "Epoch: 458 , [Discriminator :: Loss : 0.034066542983055115] , [Generator :: Loss : 4.352165699005127]\n",
            "Epoch: 459 , [Discriminator :: Loss : 0.045933134853839874] , [Generator :: Loss : 2.9041919708251953]\n",
            "Epoch: 460 , [Discriminator :: Loss : 0.2923680245876312] , [Generator :: Loss : 4.095399379730225]\n",
            "Epoch: 461 , [Discriminator :: Loss : 0.004684842191636562] , [Generator :: Loss : 3.6734070777893066]\n",
            "Epoch: 462 , [Discriminator :: Loss : 0.06267467141151428] , [Generator :: Loss : 4.18859338760376]\n",
            "Epoch: 463 , [Discriminator :: Loss : 0.04283716157078743] , [Generator :: Loss : 4.037502288818359]\n",
            "Epoch: 464 , [Discriminator :: Loss : 0.06545735895633698] , [Generator :: Loss : 4.3632893562316895]\n",
            "Epoch: 465 , [Discriminator :: Loss : 0.02303363010287285] , [Generator :: Loss : 4.0581374168396]\n",
            "Epoch: 466 , [Discriminator :: Loss : 0.04499012976884842] , [Generator :: Loss : 5.531509876251221]\n",
            "Epoch: 467 , [Discriminator :: Loss : 0.06416653096675873] , [Generator :: Loss : 4.265362739562988]\n",
            "Epoch: 468 , [Discriminator :: Loss : 0.031766217201948166] , [Generator :: Loss : 4.124375820159912]\n",
            "Epoch: 469 , [Discriminator :: Loss : 0.11348909139633179] , [Generator :: Loss : 4.111712455749512]\n",
            "Epoch: 470 , [Discriminator :: Loss : 0.08045206218957901] , [Generator :: Loss : 4.728601932525635]\n",
            "Epoch: 471 , [Discriminator :: Loss : 0.02956000342965126] , [Generator :: Loss : 3.6710562705993652]\n",
            "Epoch: 472 , [Discriminator :: Loss : 0.3932523727416992] , [Generator :: Loss : 4.545726299285889]\n",
            "Epoch: 473 , [Discriminator :: Loss : 0.06679756194353104] , [Generator :: Loss : 5.6037750244140625]\n",
            "Epoch: 474 , [Discriminator :: Loss : 0.14227911829948425] , [Generator :: Loss : 3.4684879779815674]\n",
            "Epoch: 475 , [Discriminator :: Loss : 0.018944352865219116] , [Generator :: Loss : 4.440284252166748]\n",
            "Epoch: 476 , [Discriminator :: Loss : 0.14918716251850128] , [Generator :: Loss : 5.440645694732666]\n",
            "Epoch: 477 , [Discriminator :: Loss : 0.026691503822803497] , [Generator :: Loss : 4.52603816986084]\n",
            "Epoch: 478 , [Discriminator :: Loss : 0.06645587831735611] , [Generator :: Loss : 5.208890438079834]\n",
            "Epoch: 479 , [Discriminator :: Loss : 0.04148269444704056] , [Generator :: Loss : 5.019356727600098]\n",
            "Epoch: 480 , [Discriminator :: Loss : 0.021630102768540382] , [Generator :: Loss : 4.197356224060059]\n",
            "Epoch: 481 , [Discriminator :: Loss : 0.20911869406700134] , [Generator :: Loss : 3.93818998336792]\n",
            "Epoch: 482 , [Discriminator :: Loss : 0.057331282645463943] , [Generator :: Loss : 3.3560497760772705]\n",
            "Epoch: 483 , [Discriminator :: Loss : 0.10217919200658798] , [Generator :: Loss : 2.816787004470825]\n",
            "Epoch: 484 , [Discriminator :: Loss : 0.4767172336578369] , [Generator :: Loss : 2.6872141361236572]\n",
            "Epoch: 485 , [Discriminator :: Loss : 0.027118230238556862] , [Generator :: Loss : 3.109914779663086]\n",
            "Epoch: 486 , [Discriminator :: Loss : 0.33978188037872314] , [Generator :: Loss : 4.008736610412598]\n",
            "Epoch: 487 , [Discriminator :: Loss : 0.12149539589881897] , [Generator :: Loss : 4.881633758544922]\n",
            "Epoch: 488 , [Discriminator :: Loss : 0.026798943057656288] , [Generator :: Loss : 5.132777214050293]\n",
            "Epoch: 489 , [Discriminator :: Loss : 0.09263769537210464] , [Generator :: Loss : 5.828693866729736]\n",
            "Epoch: 490 , [Discriminator :: Loss : 0.22766602039337158] , [Generator :: Loss : 5.028014659881592]\n",
            "Epoch: 491 , [Discriminator :: Loss : 0.0812409445643425] , [Generator :: Loss : 4.750699996948242]\n",
            "Epoch: 492 , [Discriminator :: Loss : 0.025517337024211884] , [Generator :: Loss : 3.525672435760498]\n",
            "Epoch: 493 , [Discriminator :: Loss : 0.04660681262612343] , [Generator :: Loss : 3.117304563522339]\n",
            "Epoch: 494 , [Discriminator :: Loss : 0.016053689643740654] , [Generator :: Loss : 2.8628339767456055]\n",
            "Epoch: 495 , [Discriminator :: Loss : 0.033105116337537766] , [Generator :: Loss : 2.992902994155884]\n",
            "Epoch: 496 , [Discriminator :: Loss : 0.33042317628860474] , [Generator :: Loss : 3.8231375217437744]\n",
            "Epoch: 497 , [Discriminator :: Loss : 0.1069231629371643] , [Generator :: Loss : 3.4659228324890137]\n",
            "Epoch: 498 , [Discriminator :: Loss : 0.11192400753498077] , [Generator :: Loss : 4.464672088623047]\n",
            "Epoch: 499 , [Discriminator :: Loss : 0.04055921360850334] , [Generator :: Loss : 5.088396072387695]\n"
          ]
        }
      ]
    }
  ]
}